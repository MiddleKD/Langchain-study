{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANG_SMITH\")\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# 지식 베이스 생성 및 벡터 저장\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 템플릿과 rag chain 생성\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "##--- Lagacy ----##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history기반 대화 RAG 리트리버 만들기\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적인 RAG 체인 만들기. 단, chat hisory가 프롬프트화 됨\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several common approaches to task decomposition:\n",
      "\n",
      "User Input: What are common ways of doing task decomposition?\n",
      "\n",
      "Task Planning:\n",
      "1. Identify different techniques for task decomposition\n",
      "2. Explain each technique briefly with examples\n",
      "3. Highlight the pros and cons of different approaches\n",
      "\n",
      "Model Selection: \n",
      "1. Leverage my own knowledge about project management and task planning\n",
      "2. Refer to the given context about chain of thought prompting for examples\n",
      "\n",
      "Task Execution:\n",
      "Some common ways of performing task decomposition include:\n",
      "\n",
      "1. Top-down approach: This involves starting with the overall big task and successively breaking it down into smaller sub-tasks or components in a hierarchical manner. For example, when planning a wedding, the top-level task is \"Plan the wedding\", which can be broken down into venues, catering, guest list, etc.\n",
      "\n",
      "2. Bottom-up approach: Here you start by identifying the basic actionable steps first, and then combine related steps into higher-level tasks or goals. For instance, when writing a book, lower-level tasks could be researching, outlining, writing chapters which roll up into the higher goal of completing the manuscript.\n",
      "\n",
      "3. Hierarchical task analysis: This is a structured approach that examines the hierarchical decomposition of goals into sub-goals iteratively. It lays out tasks, sub-tasks, conditions, input/outputs in a detailed diagrammatic form. Commonly used for complex systems design.\n",
      "\n",
      "4. Goal-oriented task analysis: This technique decomposes goals or objectives into the required criteria or sub-goals needed to achieve the higher-level goal. A good approach when goals are well-defined upfront.\n",
      "\n",
      "5. Using prompting techniques like Chain of Thought: Providing step-by-step instructions to language models to break down tasks into simpler steps and thoughts. For example: \"To solve this math word problem: 1) Identify the known values 2) Figure out what needs to be calculated...\"\n",
      "\n",
      "The top-down and bottom-up approaches are intuitive ways for humans to decompose tasks. Structured approaches like HTA are more formal but important for complex system design. Chain of thought prompting shows how AI can also aid in task decomposition.\n"
     ]
    }
   ],
   "source": [
    "# 히스토리 기반 대화\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "question = \"What is Task Decomposition?\"\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=ai_msg_1[\"answer\"]),\n",
    "    ]\n",
    ")\n",
    "second_question = \"What are common ways of doing it?\"\n",
    "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "\n",
    "print(ai_msg_2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 히스토리 관리\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is the process of breaking down a complex task into smaller, more manageable subtasks or steps. It involves identifying the different components or subgoals required to achieve the overall objective.\\n\\nTask Planning: The key steps involved in task decomposition are:\\n1. Understand the overall task or goal\\n2. Identify the main subtasks or components needed to accomplish the goal\\n3. Break down each subtask further into smaller steps if needed\\n4. Determine the order or sequence in which the subtasks should be performed\\n\\nModel Selection: To perform task decomposition for the given query, I will use my own knowledge and reasoning capabilities as a large language model.\\n\\nTask Execution: The retrieved context explains task decomposition techniques used by AI systems like Chain of Thought (CoT) and Tree of Thoughts. CoT prompts the model to \"think step-by-step\" to decompose a hard task into simpler steps. Tree of Thoughts extends this by exploring multiple reasoning paths at each step, creating a tree-like structure of possible solution paths. The context also mentions that task decomposition can be done by the language model itself through simple prompts, by using task-specific instructions, or with human input. Task decomposition helps break down complex problems into more manageable components, making it easier to reason about and solve the overall task.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 히스토리 생성\n",
    "\n",
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What is Task Decomposition?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are a few common approaches to task decomposition:\\n\\n1. Top-down decomposition: Start with the overall task or goal, and break it down into major subtasks or components. Then further decompose each subtask into smaller steps until you reach an actionable level.\\n\\n2. Bottom-up decomposition: Identify the basic actionable steps first, and then group and sequence them into higher-level subtasks that ultimately accomplish the overall goal.\\n\\n3. Hierarchical decomposition: Combine aspects of top-down and bottom-up approaches. Decompose the task into major components top-down, then decompose each component bottom-up into actionable steps.\\n\\n4. Technique-based decomposition: Use domain knowledge, templates or specific techniques for the type of task. For example, writing an outline when decomposing a writing task.\\n\\n5. Question-based decomposition: Ask questions like \"What are the steps to achieve X?\" or \"What subgoals do I need to complete X?\" to prompt decomposition.\\n\\n6. Tool-assisted decomposition: Use tools, diagrams like hierarchical task analysis, flow charts or AI/LLM assistance to aid the decomposition process.\\n\\nThe context mentions a few of these - using simple prompts, task-specific instructions, or human input to guide an LLM in decomposing tasks into steps. Choosing the right approach depends on the task complexity and available knowledge/resources.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 히스토리 생성 제대로 되는지 확인\n",
    "\n",
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What are common ways of doing it?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is Task Decomposition?\n",
      "\n",
      "AI: Task decomposition is the process of breaking down a complex task into smaller, more manageable subtasks or steps. It involves identifying the different components or subgoals required to achieve the overall objective.\n",
      "\n",
      "Task Planning: The key steps involved in task decomposition are:\n",
      "1. Understand the overall task or goal\n",
      "2. Identify the main subtasks or components needed to accomplish the goal\n",
      "3. Break down each subtask further into smaller steps if needed\n",
      "4. Determine the order or sequence in which the subtasks should be performed\n",
      "\n",
      "Model Selection: To perform task decomposition for the given query, I will use my own knowledge and reasoning capabilities as a large language model.\n",
      "\n",
      "Task Execution: The retrieved context explains task decomposition techniques used by AI systems like Chain of Thought (CoT) and Tree of Thoughts. CoT prompts the model to \"think step-by-step\" to decompose a hard task into simpler steps. Tree of Thoughts extends this by exploring multiple reasoning paths at each step, creating a tree-like structure of possible solution paths. The context also mentions that task decomposition can be done by the language model itself through simple prompts, by using task-specific instructions, or with human input. Task decomposition helps break down complex problems into more manageable components, making it easier to reason about and solve the overall task.\n",
      "\n",
      "User: What are common ways of doing it?\n",
      "\n",
      "AI: There are a few common approaches to task decomposition:\n",
      "\n",
      "1. Top-down decomposition: Start with the overall task or goal, and break it down into major subtasks or components. Then further decompose each subtask into smaller steps until you reach an actionable level.\n",
      "\n",
      "2. Bottom-up decomposition: Identify the basic actionable steps first, and then group and sequence them into higher-level subtasks that ultimately accomplish the overall goal.\n",
      "\n",
      "3. Hierarchical decomposition: Combine aspects of top-down and bottom-up approaches. Decompose the task into major components top-down, then decompose each component bottom-up into actionable steps.\n",
      "\n",
      "4. Technique-based decomposition: Use domain knowledge, templates or specific techniques for the type of task. For example, writing an outline when decomposing a writing task.\n",
      "\n",
      "5. Question-based decomposition: Ask questions like \"What are the steps to achieve X?\" or \"What subgoals do I need to complete X?\" to prompt decomposition.\n",
      "\n",
      "6. Tool-assisted decomposition: Use tools, diagrams like hierarchical task analysis, flow charts or AI/LLM assistance to aid the decomposition process.\n",
      "\n",
      "The context mentions a few of these - using simple prompts, task-specific instructions, or human input to guide an LLM in decomposing tasks into steps. Choosing the right approach depends on the task complexity and available knowledge/resources.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in store[\"abc123\"].messages:\n",
    "    if isinstance(message, AIMessage):\n",
    "        prefix = \"AI\"\n",
    "    else:\n",
    "        prefix = \"User\"\n",
    "\n",
    "    print(f\"{prefix}: {message.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 결합하기 위해 tool 만들기\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"blog_post_retriever\",\n",
    "    \"Searches and returns excerpts from the Autonomous Agents blog post.\"\n",
    ")\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke(\"task decomposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 만들기\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(llm, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=[{'id': 'toolu_018V7hdT6thtyskL5H347G7H', 'input': {'query': 'Task Decomposition'}, 'name': 'blog_post_retriever', 'type': 'tool_use'}], response_metadata={'id': 'msg_014pHCLdR8CBByW5SPmPA1G5', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 253, 'output_tokens': 59}}, id='run-10db4db5-1b56-47ba-8da5-94faa63b74b5-0', tool_calls=[{'name': 'blog_post_retriever', 'args': {'query': 'Task Decomposition'}, 'id': 'toolu_018V7hdT6thtyskL5H347G7H', 'type': 'tool_call'}], usage_metadata={'input_tokens': 253, 'output_tokens': 59, 'total_tokens': 312})]}}\n",
      "-----\n",
      "{'tools': {'messages': [ToolMessage(content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:', name='blog_post_retriever', tool_call_id='toolu_018V7hdT6thtyskL5H347G7H')]}}\n",
      "-----\n",
      "{'agent': {'messages': [AIMessage(content='Task decomposition is the process of breaking down a complex task or problem into smaller, more manageable sub-tasks or steps. This helps in understanding and solving the overall problem in a structured and organized manner.\\n\\nThe key aspects of task decomposition are:\\n\\n1. Identifying the overall goal or task.\\n2. Breaking it down into a sequence of sub-tasks or steps required to achieve the goal.\\n3. Arranging the sub-tasks in a logical order, considering dependencies and constraints.\\n4. Assigning responsibilities or allocating resources for each sub-task.\\n5. Tracking progress and completion of each sub-task.\\n\\nTask decomposition is a vital step in planning and problem-solving for both humans and AI systems. It helps in managing complexity, parallelizing work, and maintaining a clear overview of the entire process.\\n\\nFor an AI assistant like myself, the task decomposition process would involve:\\n\\nUser Input: \"What is Task Decomposition?\"\\n\\nTask Planning: \\n1. Understand the user\\'s query about \"Task Decomposition\"\\n2. Retrieve relevant information about task decomposition from my knowledge base\\n3. Organize and structure the information into a coherent explanation\\n\\nModel Selection: My language model capabilities are utilized for all tasks.\\n\\nTask Execution:\\n1. I comprehended the query asking for an explanation of task decomposition.\\n2. I searched my training data for information related to task decomposition and its role in problem-solving.\\n3. I composed the explanation by defining task decomposition, listing its key aspects, and describing how it applies to AI systems like myself.\\n\\nThe explanation I provided covers the core concept of task decomposition and how it helps in breaking down complex problems into more manageable steps in a structured way. I outlined the key steps involved and highlighted its importance for both humans and AI in planning and problem-solving. My response aims to directly answer the user\\'s query in a clear and informative manner based on the relevant knowledge retrieved from my training.', response_metadata={'id': 'msg_01GqYaqJXwJdVx6GwkCRt6PJ', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 867, 'output_tokens': 428}}, id='run-457c7d95-2426-41d1-a764-81da5ffa770f-0', usage_metadata={'input_tokens': 867, 'output_tokens': 428, 'total_tokens': 1295})]}}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Tool의 사용을 유도하여 질문하기\n",
    "\n",
    "query = \"What is Task Decomposition? find document.\"\n",
    "\n",
    "for s in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=query)]},\n",
    "):\n",
    "    print(s)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langgraph로 history 저장소 만들어서 대화하기\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "agent_executor = create_react_agent(llm, tools, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"Hello Bob, nice to meet you! I'm an AI assistant created by Anthropic to be helpful, harmless, and honest. How can I assist you today?\", response_metadata={'id': 'msg_01CwkqjHzzAvTsLifMR8zwp6', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 248, 'output_tokens': 38}}, id='run-4c893e0d-2848-4e51-969c-d7bae5f72531-0', usage_metadata={'input_tokens': 248, 'output_tokens': 38, 'total_tokens': 286})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "for s in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Hi! I'm bob\")]}, config=config\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=[{'text': 'Okay, let me search the Autonomous Agents blog post for relevant information on task decomposition.', 'type': 'text'}, {'id': 'toolu_01TTvt7axuX4DvtxouzpZj9p', 'input': {'query': 'task decomposition'}, 'name': 'blog_post_retriever', 'type': 'tool_use'}], response_metadata={'id': 'msg_01Y4uBNP9yXvoyVLFpJmmrwj', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 571, 'output_tokens': 78}}, id='run-1fb5b7d2-b9d4-4d6a-81ae-c2d3fd0e420f-0', tool_calls=[{'name': 'blog_post_retriever', 'args': {'query': 'task decomposition'}, 'id': 'toolu_01TTvt7axuX4DvtxouzpZj9p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 571, 'output_tokens': 78, 'total_tokens': 649})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:', name='blog_post_retriever', tool_call_id='toolu_01TTvt7axuX4DvtxouzpZj9p')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='The blog post discusses how large language models like GPT can be used for task decomposition - breaking down a complex task into smaller, more manageable sub-tasks. Some key points on task decomposition from the post:\\n\\n- Task decomposition helps simplify complex tasks by dividing them into a sequence of smaller steps. This makes it easier for the AI model to tackle each component.\\n\\n- Different techniques are mentioned for prompting the LLM to do task decomposition, like asking \"What are the steps/subgoals for achieving X?\" or providing task-specific instructions like \"Write a story outline.\"\\n\\n- The chain-of-thought (CoT) prompting paradigm prompts the model to \"think step-by-step\" and decompose the task into simpler steps that the model reasons through.\\n\\n- Tree of Thoughts extends CoT by exploring multiple possible reasoning paths at each step, creating a tree structure of thoughts to find the best solution.\\n\\n- Task decomposition by an LLM is a key initial stage before subtasks are executed by specialist models in an AI system.\\n\\nSo in summary, large language models can break down complex problems by analyzing the overall goal and generating a sequence of more granular subtasks or steps required to accomplish it. This decomposition into simpler parts makes the problems more tractable.', response_metadata={'id': 'msg_01UyBsTVjPeGPdWSfxf6VBXs', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 1205, 'output_tokens': 282}}, id='run-84bd859a-d285-419d-9f4a-38181686fe74-0', usage_metadata={'input_tokens': 1205, 'output_tokens': 282, 'total_tokens': 1487})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Task Decomposition? find document\"\n",
    "\n",
    "for s in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=query)]}, config=config\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
